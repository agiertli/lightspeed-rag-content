# Deploying hosted control planes on IBM Power


You can deploy hosted control planes by configuring a cluster to function as a hosting cluster. The hosting cluster is an Red Hat OpenShift Container Platform cluster where the control planes are hosted. The hosting cluster is also known as the management cluster.

[NOTE]
----
The management cluster is not the managed cluster. A managed cluster is a cluster that the hub cluster manages.
----
The multicluster engine Operator supports only the default local-cluster, which is a hub cluster that is managed, and the hub cluster as the hosting cluster.
To provision hosted control planes on bare metal, you can use the Agent platform. The Agent platform uses the central infrastructure management service to add worker nodes to a hosted cluster. For more information, see "Enabling the central infrastructure management service".
Each IBM Power host must be started with a Discovery Image that the central infrastructure management provides. After each host starts, it runs an Agent process to discover the details of the host and completes the installation. An Agent custom resource represents each host.
When you create a hosted cluster with the Agent platform, HyperShift installs the Agent Cluster API provider in the hosted control plane namespace.

# Prerequisites to configure hosted control planes on IBM Power

* The multicluster engine for Kubernetes Operator version 2.7 and later installed on an Red Hat OpenShift Container Platform cluster. The multicluster engine Operator is automatically installed when you install Red Hat Advanced Cluster Management (RHACM). You can also install the multicluster engine Operator without RHACM as an Operator from the Red Hat OpenShift Container Platform OperatorHub.
* The multicluster engine Operator must have at least one managed Red Hat OpenShift Container Platform cluster. The local-cluster managed hub cluster is automatically imported in the multicluster engine Operator version 2.7 and later. For more information about local-cluster, see Advanced configuration in the RHACM documentation. You can check the status of your hub cluster by running the following command:

```terminal
$ oc get managedclusters local-cluster
```

* You need a hosting cluster with at least 3 worker nodes to run the HyperShift Operator.
* You need to enable the central infrastructure management service. For more information, see "Enabling the central infrastructure management service".
* You need to install the hosted control plane command-line interface. For more information, see "Installing the hosted control plane command-line interface".

The hosted control planes feature is enabled by default. If you disabled the feature and want to manually enable it, see "Manually enabling the hosted control planes feature". If you need to disable the feature, see "Disabling the hosted control planes feature".

* Advanced configuration
* Enabling the central infrastructure management service
* Installing the hosted control planes command-line interface
* Manually enabling the hosted control planes feature
* Disabling the hosted control planes feature

# IBM Power infrastructure requirements

The Agent platform does not create any infrastructure, but requires the following resources for infrastructure:

* Agents: An Agent represents a host that is booted with a discovery image and is ready to be provisioned as an Red Hat OpenShift Container Platform node.
* DNS: The API and Ingress endpoints must be routable.

# DNS configuration for hosted control planes on IBM Power

The API server for the hosted cluster is exposed. A DNS entry must exist for the api.<hosted_cluster_name>.<basedomain> entry that points to the destination where the API server is reachable.

The DNS entry can be as simple as a record that points to one of the nodes in the managed cluster that is running the hosted control plane.

The entry can also point to a load balancer that is deployed to redirect incoming traffic to the ingress pods.

See the following example of a DNS configuration:


```terminal
$ cat /var/named/<example.krnl.es.zone>
```



```terminal
$ TTL 900
@ IN  SOA bastion.example.krnl.es.com. hostmaster.example.krnl.es.com. (
      2019062002
      1D 1H 1W 3H )
  IN NS bastion.example.krnl.es.com.
;
;
api                   IN A 1xx.2x.2xx.1xx 1
api-int               IN A 1xx.2x.2xx.1xx
;
;
*.apps.<hosted-cluster-name>.<basedomain>           IN A 1xx.2x.2xx.1xx
;
;EOF
```


The record refers to the IP address of the API load balancer that handles ingress and egress traffic for hosted control planes.

For IBM Power, add IP addresses that correspond to the IP address of the agent.


```terminal
compute-0              IN A 1xx.2x.2xx.1yy
compute-1              IN A 1xx.2x.2xx.1yy
```


# Creating a hosted cluster on bare metal

When you create a hosted cluster with the Agent platform, HyperShift installs the Agent Cluster API provider in the hosted control plane namespace. You can create a hosted cluster on bare metal or import one.

As you create a hosted cluster, keep the following guidelines in mind:

* Each hosted cluster must have a cluster-wide unique name. A hosted cluster name cannot be the same as any existing managed cluster in order for multicluster engine Operator to manage it.
* Do not use clusters as a hosted cluster name.
* A hosted cluster cannot be created in the namespace of a multicluster engine Operator managed cluster.

1. Create the hosted control plane namespace by entering the following command:

```terminal
$ oc create ns <hosted_cluster_namespace>-<hosted_cluster_name>
```


Replace <hosted_cluster_namespace> with your hosted cluster namespace name, for example, clusters. Replace <hosted_cluster_name> with your hosted cluster name.
2. Verify that you have a default storage class configured for your cluster. Otherwise, you might see pending PVCs. Run the following command:

```terminal
$ hcp create cluster agent \
    --name=<hosted_cluster_name> \1
    --pull-secret=<path_to_pull_secret> \2
    --agent-namespace=<hosted_control_plane_namespace> \3
    --base-domain=<basedomain> \4
    --api-server-address=api.<hosted_cluster_name>.<basedomain> \5
    --etcd-storage-class=<etcd_storage_class> \6
    --ssh-key  <path_to_ssh_public_key> \7
    --namespace <hosted_cluster_namespace> \8
    --control-plane-availability-policy HighlyAvailable \9
    --release-image=quay.io/openshift-release-dev/ocp-release:<ocp_release_image> 10
```

Specify the name of your hosted cluster, for instance, example.
Specify the path to your pull secret, for example, /user/name/pullsecret.
Specify your hosted control plane namespace, for example, clusters-example. Ensure that agents are available in this namespace by using the oc get agent -n <hosted_control_plane_namespace> command.
Specify your base domain, for example, krnl.es.
The --api-server-address flag defines the IP address that is used for the Kubernetes API communication in the hosted cluster. If you do not set the --api-server-address flag, you must log in to connect to the management cluster.
Specify the etcd storage class name, for example, lvm-storageclass.
Specify the path to your SSH public key. The default file path is ~/.ssh/id_rsa.pub.
Specify your hosted cluster namespace.
The default value for the control plane availability policy is HighlyAvailable.
Specify the supported Red Hat OpenShift Container Platform version that you want to use, for example, 4.14.0-x86_64. If you are using a disconnected environment, replace <ocp_release_image> with the digest image. To extract the Red Hat OpenShift Container Platform release image digest, see Extracting the Red Hat OpenShift Container Platform release image digest.
3. After a few moments, verify that your hosted control plane pods are up and running by entering the following command:

```terminal
$ oc -n <hosted_control_plane_namespace> get pods
```

Example output

```terminal
NAME                                             READY   STATUS    RESTARTS   AGE
capi-provider-7dcf5fc4c4-nr9sq                   1/1     Running   0          4m32s
catalog-operator-6cd867cc7-phb2q                 2/2     Running   0          2m50s
certified-operators-catalog-884c756c4-zdt64      1/1     Running   0          2m51s
cluster-api-f75d86f8c-56wfz                      1/1     Running   0          4m32s
```
